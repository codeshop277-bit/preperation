# Docker
Docker is a containerization platform that packages your application along with all its dependencies (runtime, libraries, configs, system tools) into a container.
A container runs the same way:
On your laptop
On staging
On production
On cloud servers
It eliminates environment mismatch problems.
1ï¸âƒ£ Environment Consistency
Prevents:
â€œWorks on my machineâ€ problems
Your app runs identically everywhere.
2ï¸âƒ£ Dependency Isolation
Different projects can use:
Different Node versions
Different Python versions
Different system libraries
Without conflict.
3ï¸âƒ£ Simplified Deployment
Instead of configuring servers manually, you:
Build a Docker image
Deploy the container
Infrastructure becomes predictable.
4ï¸âƒ£ Scalability & Microservices
Modern systems use:
Microservices
Kubernetes
Cloud-native architecture
Docker is the standard packaging unit for these systems.
5ï¸âƒ£ Faster Onboarding
New developer just runs:
docker-compose up
No manual setup chaos.
ğŸ§  In One Line
Docker ensures:
Your application runs consistently, predictably, and portably across all environments.

# Image VS Container
A Docker image is a static template containing the application and its dependencies, while a container is a running instance of that image.
| Docker Image        | Docker Container      |
| ------------------- | --------------------- |
| Static              | Running               |
| Blueprint           | Instance              |
| Read-only           | Writable layer        |
| Stored in registry  | Runs on Docker engine |
| Doesnâ€™t consume CPU | Consumes CPU & RAM    |
You build an image:
docker build -t my-react-app .
Now you have:
my-react-app (image)
When you run:
docker run my-react-app
Now you have:
container #1 running
Run it again:
docker run my-react-app
Now you have:
container #2 running

# Docker Layer
A Docker image is built in layers.
Every instruction in your Dockerfile creates a new layer.
Example:
FROM node:20
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
RUN npm run build
Each of these lines = one layer.
So your image isnâ€™t one big file.
Itâ€™s a stack of layered filesystems.
How Layers Work Internally
When Docker builds an image:
1ï¸âƒ£ It pulls the base image (node:20) â†’ base layer
2ï¸âƒ£ Adds a layer for WORKDIR
3ï¸âƒ£ Adds a layer for COPY package.json
4ï¸âƒ£ Adds a layer for RUN npm install
5ï¸âƒ£ Adds a layer for COPY . .
6ï¸âƒ£ Adds a layer for RUN npm run build
Each layer:
Is immutable
Is cached
Is reused if unchanged
Why Layers Are Powerful
1ï¸âƒ£ Caching (Huge for performance)
Letâ€™s say you only change a React component.
Docker rebuild process:
Base image â†’ cached
npm install â†’ cached (because package.json didnâ€™t change)
Only COPY . . and npm run build re-run
So build becomes FAST âš¡
This is why order in Dockerfile matters.
ğŸ”¥ Layer Reuse Across Images
Hereâ€™s the cool part.
If two projects use:
FROM node:20
Docker does NOT download it twice.
That base layer is shared.
Same on your system:
Multiple images can share the same base layers.
Space efficient + bandwidth efficient.
ğŸ“¦ What Happens When a Container Runs?
When you start a container:
Docker adds one extra layer on top:
ğŸŸ¢ Writable layer
All runtime changes go there.
Example:
App writes logs
Temporary files created
Runtime cache
Those changes DO NOT modify the image.
Image remains clean.
Container gets its own writable layer.
ğŸ§© Image = Read-only layers
ğŸ“¦ Container = Image layers + 1 writable layer
Thatâ€™s the key architecture.
Why Deleting Containers Doesnâ€™t Remove Images
Because:
Containers sit on top of images
Images are separate layered filesystem objects
You can:
Delete container â†’ image still exists
Delete image â†’ containers depending on it break

One-Line Interview Answer
Docker images are composed of multiple immutable layers created by each Dockerfile instruction. These layers are cached and shared, improving build performance and storage efficiency.
# Best Practices
1ï¸âƒ£ Use a Small Base Image
Bad:
FROM node:latest
Better:
FROM node:20-alpine
Why?
Smaller image size
Faster pull
Less attack surface
Better security
Alpine = lightweight Linux.
2ï¸âƒ£ Use Multi-Stage Builds (VERY Important)
For React / Node apps:
# Stage 1: Build
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build
# Stage 2: Production
FROM nginx:alpine
COPY --from=builder /app/build /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
Why?
Dev dependencies donâ€™t go to production
Smaller final image
More secure
Cleaner separation
This is industry standard.
3ï¸âƒ£ Leverage Layer Caching Properly
Order matters.
Correct:
COPY package*.json ./
RUN npm ci
COPY . .
Wrong:
COPY . .
RUN npm ci
Why?
Because any file change forces npm install again. Slow builds.
4ï¸âƒ£ Use .dockerignore
Very underrated.
Create .dockerignore:
node_modules
.git
dist
build
.env
Why?
Prevents unnecessary files from being copied
Smaller build context
Faster builds
More secure
5ï¸âƒ£ Donâ€™t Use latest Tag
Bad:
FROM node:latest
Better:
FROM node:20.10-alpine
Why?
latest changes unexpectedly â†’ production breaks randomly.
Version pinning = predictable builds.
6ï¸âƒ£ Use npm ci Instead of npm install
Why?
Faster
Uses lockfile strictly
Reproducible builds
Better for CI/CD
7ï¸âƒ£ Run as Non-Root User (Security)
By default containers run as root. Not ideal.
Better:
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser
Prevents privilege escalation if compromised.
Security teams love this.
8ï¸âƒ£ Keep Image Small
Tips:
Remove unnecessary tools
Use multi-stage builds
Avoid installing build tools in production stage
Combine RUN commands:
Instead of:
RUN apk update
RUN apk add curl
Do:
RUN apk update && apk add curl
Fewer layers.
9ï¸âƒ£ Use Health Checks
Example:
HEALTHCHECK CMD curl --fail http://localhost:3000 || exit 1
Why?
Kubernetes / ECS can detect unhealthy containers
Enables auto-restart
ğŸ”Ÿ Keep Containers Stateless
Containers should not store:
Database data
Uploaded files
Use:
Volumes
S3
RDS
Containers should be disposable.

# ğŸ“¦ Docker Volumes
â“ Why Do We Need Volumes?
By default:
Containers are ephemeral
When a container dies â†’ its data is gone
Thatâ€™s fine for:
Stateless apps
Frontend servers
Not fine for:
Databases
Uploaded files
Logs
Persistent storage
Thatâ€™s where volumes come in.
ğŸ§  What Is a Volume?
A volume is external storage managed by Docker that lives outside the container filesystem.
It survives:
Container restarts
Container deletion
ğŸ”¥ Example: Without Volume (Bad for DB)
docker run mysql
You add data.
Container crashes â†’ you remove it â†’ all data gone ğŸ’€
âœ… Example: With Volume (Correct)
docker run -v mydata:/var/lib/mysql mysql
Now:
mydata lives outside container
Container can be deleted
Data still exists
ğŸ—ï¸ Types of Storage in Docker
1ï¸âƒ£ Named Volumes (Recommended)
docker volume create myvolume
Used like:
docker run -v myvolume:/app/data
Best for:
Databases
Production setups
2ï¸âƒ£ Bind Mounts
docker run -v /host/path:/container/path
Maps host folder directly.
Best for:
Local development
Live code reload
But not ideal for production portability.
ğŸ§  Mental Model
Image = Blueprint
Container = Running process
Volume = External hard drive attached

# Networking in Docker
By default, containers are isolated.
They donâ€™t magically talk to each other.
Docker provides networking drivers.
ğŸ—ï¸ Default Network (Bridge)
When you run:
docker run nginx
Docker attaches container to a bridge network.
It gets:
Internal IP
Can talk to other containers in same network
ğŸ”¥ Example: Backend + DB Communication
Instead of:
localhost:3306
In Docker:
If both are in same network:
mysql:3306
Docker provides internal DNS.
Container name = hostname.
ğŸ§ª Example with docker-compose
services:
  backend:
    build: .
    depends_on:
      - db
  db:
    image: mysql
Backend can connect to:
db:3306
Not localhost.
This is very important.
ğŸŒ Networking Modes
1ï¸âƒ£ Bridge (Default)
Isolated network
Containers talk internally
Most common
2ï¸âƒ£ Host Mode
Container shares host network.
docker run --network host
No port mapping needed.
Used when:
Performance critical apps
Low latency systems
3ï¸âƒ£ None
No network at all.
Security isolation use cases.
ğŸ§  Port Mapping (Important)
This exposes container port to outside world:
docker run -p 3000:3000 myapp
Meaning:
Host:3000 â†’ Container:3000
Without -p, container is internal only.

# Docker Compose
Docker Compose is a tool that lets you define and run multiple containers together using a single configuration file.
Instead of running 5 long docker commands, you write:
docker-compose up
And everything starts together.
ğŸ§  Mental Model
If Docker runs one container,
Docker Compose runs an entire application stack.
ğŸ“„ It Uses a File Called
docker-compose.yml
This file describes:
Services (containers)
Networks
Volumes
Environment variables
Dependencies
All in one place.
ğŸ”¥ Example: React + Node + MySQL
version: "3.9"
services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend

  backend:
    build: ./backend
    ports:
      - "5000:5000"
    depends_on:
      - db

  db:
    image: mysql:8
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      - db_data:/var/lib/mysql

volumes:
  db_data:
Now just run:
docker-compose up
Boom ğŸ’¥
3 containers
1 network
1 volume
Everything connected automatically
ğŸŒ Networking in Compose
All services in a compose file automatically:
Share the same network
Can talk to each other using service name
So backend connects to DB using:
db:3306
Not localhost.
This is huge.
ğŸ“¦ Volumes in Compose
We defined:
volumes:
  db_data:
This makes DB data persistent.
If you delete containers:
Data stays.
âš™ï¸ Why Docker Compose is Important
1ï¸âƒ£ Local Development
Perfect for:
Full stack apps
Microservices
Teams
Everyone runs:
docker-compose up
No setup mess.
2ï¸âƒ£ Environment Parity
Dev environment = Staging environment = Production (if designed well)
3ï¸âƒ£ Cleaner Infrastructure Definition
Instead of documentation like:
â€œFirst run DB, then backendâ€¦â€
Itâ€™s all declared in YAML.
Infrastructure as code.
ğŸš€ Compose vs Kubernetes
Compose:
Great for local
Simple production setups
Small teams
Kubernetes:
Large scale
Auto-scaling
Cloud orchestration
Compose is like:
Single-machine orchestration
ğŸ¯ One-Line Interview Answer
Docker Compose is a tool used to define and run multi-container Docker applications using a single YAML configuration file.
ğŸ§  Real World Insight
In serious production systems:
Compose â†’ Local development
ECS / Kubernetes â†’ Production
But for small apps?
Compose + EC2 works perfectly fine.

# Image Size
Why Image Size Matters
Large images cause:
ğŸ¢ Slow docker pull
ğŸ¢ Slow CI/CD pipelines
ğŸ’¸ Higher bandwidth costs
ğŸ”“ Larger attack surface
ğŸ“¦ Wasted storage in registry
Goal: Small, deterministic, production-only image
1ï¸âƒ£ Use Minimal Base Images
2ï¸âƒ£ Use Multi-Stage Builds (Most Important)
3ï¸âƒ£ Use .dockerignore
4ï¸âƒ£ Combine RUN Commands
5ï¸âƒ£ Use npm ci + Production Only
6ï¸âƒ£ Clean Package Manager Cache
7ï¸âƒ£ Avoid Installing Unnecessary Tools
Donâ€™t install:
curl
git
vim
bash
Unless absolutely required.
Every installed tool increases size.
ğŸš€ 9ï¸âƒ£ Analyze Image Size
Use:
docker history <image>
Shows layer sizes.
Or use tools like:
dive (image analyzer)
This helps identify bloated layers.
ğŸš€ ğŸ”¥ Example: Size Comparison
Typical Node app:
Without optimization â†’ 900MB
With Alpine + multi-stage â†’ 150MB
With distroless â†’ 80â€“120MB
Huge difference.
ğŸ§  Advanced: Distroless Images
Instead of:
FROM node:alpine
Use:
gcr.io/distroless/nodejs
No shell, no package manager.
Extremely minimal.
More secure.
Smaller.
ğŸ¯ Interview One-Liner
Image size can be optimized using minimal base images, multi-stage builds, proper layer ordering, .dockerignore, removing dev dependencies, and cleaning package manager caches.

# Security best practices
Secure Production Container Checklist
âœ” Minimal base image
âœ” Multi-stage build
âœ” Non-root user
By default, containers run as root.
Thatâ€™s dangerous.
If attacker compromises container:
Root inside container can sometimes escalate to host.
Use:
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser
Now container runs with limited permissions.
âœ” No secrets in image
Instead:
Use environment variables at runtime
Use AWS Secrets Manager
Use Docker secrets
Use Kubernetes secrets
Images should be generic, secrets injected at runtime.
âœ” Image scanning enabled
âœ” Limited resources
âœ” Only required ports exposed
Database containers should NOT be publicly exposed.
Keep them internal network only.
âœ” Regular updates
Use Read-Only Filesystem (Advanced)
You can run container as:
docker run --read-only
Prevents file system tampering.
Good for stateless apps.
# ENV vs ARG in Docker
Both define variables.
But they live in different lifecycles.
ğŸŸ¢ ARG (Build-Time Variable)
Available only during image build
Not available in running container (unless passed to ENV)
Used mainly for:
Versioning
Conditional builds
Customizing base image
Example:
ARG NODE_VERSION=20
FROM node:${NODE_VERSION}-alpine
Build with:
docker build --build-arg NODE_VERSION=18 .
After build finishes?
ğŸ‘‰ ARG disappears.
Container cannot access it.
ğŸŸ¢ ENV (Runtime Variable)
Available during build
Also available in running container
Persists in final image
Used for:
Config values
App environment
Production flags
Example:
ENV NODE_ENV=production
Now inside container:
echo $NODE_ENV
Youâ€™ll see:
production
| Feature                | ARG | ENV               |
| ---------------------- | --- | ----------------- |
| Available during build | âœ…   | âœ…                 |
| Available at runtime   | âŒ   | âœ…                 |
| Stored in final image  | âŒ   | âœ…                 |
| Override at build time | âœ…   | âŒ                 |
| Override at runtime    | âŒ   | âœ… (docker run -e) |
Good Use Case for ARG
ARG APP_VERSION
LABEL version=$APP_VERSION
You pass version during build.
Good Use Case for ENV
ENV PORT=3000
ENV NODE_ENV=production
Your app reads these at runtime.
Interview One-Liner
ARG is used for build-time variables and does not persist in the final container, whereas ENV defines environment variables that are available both during build and at runtime.