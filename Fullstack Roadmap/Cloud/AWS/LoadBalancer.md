ðŸ”€ What is a Load Balancer?
A Load Balancer (LB) distributes incoming traffic across multiple servers (EC2 instances, containers, etc.) to:
âœ… Improve availability
âœ… Increase scalability
âœ… Prevent server overload
âœ… Enable zero-downtime deployments
In AWS, load balancers are provided under Elastic Load Balancing (ELB).

ðŸ‘‰ What is ALB?
Application Load Balancer works at:
Layer 7 (Application Layer) of OSI model
Understands HTTP / HTTPS
It makes routing decisions based on:
URL path (/api, /login)
Hostname (api.example.com)
HTTP headers
Query parameters

âœ… When to Use ALB?
Web applications
REST APIs
Microservices
Container-based apps (ECS, EKS)
Next.js frontend + Node backend

ðŸ”¥ Example
If you have:
/api/* â†’ Backend EC2
/images/* â†’ Static service
admin.example.com â†’ Admin app
ALB can route based on these rules.

â­ Key Features
Path-based routing
Host-based routing
WebSockets support
Integrated with AWS WAF
SSL termination
Sticky sessions supported

2ï¸âƒ£ Network Load Balancer (NLB)
ðŸ‘‰ What is NLB?
Network Load Balancer works at:
Layer 4 (Transport Layer)
Handles TCP / UDP / TLS
It does NOT inspect HTTP content.
It routes based only on:
IP
Port

âœ… When to Use NLB?
High-performance systems
Low-latency trading systems
Real-time gaming
WebSocket heavy traffic
When you need static IP

â­ Key Features
Extremely high performance
Millions of requests per second
Ultra low latency
Static IP support
Preserves client IP

| Feature         | ALB                    | NLB                   |
| --------------- | ---------------------- | --------------------- |
| OSI Layer       | Layer 7                | Layer 4               |
| Protocol        | HTTP/HTTPS             | TCP/UDP/TLS           |
| Routing         | Path/Host/Header based | IP + Port only        |
| Static IP       | âŒ No                   | âœ… Yes                 |
| Best for        | Web apps, APIs         | High performance apps |
| SSL termination | Yes                    | Yes                   |
| Cost            | Slightly higher        | Slightly lower        |


3ï¸âƒ£ Sticky Sessions (Session Affinity)
ðŸ‘‰ What is it?
Sticky session means:
A user is always routed to the same backend server for a certain time.
ðŸŽ¯ Why needed?
Suppose:
User logs in
Session is stored in server memory
If next request goes to another server:
User will be logged out âŒ
Sticky session solves this.

ðŸ”¥ How It Works in ALB
ALB uses a cookie
Cookie contains target information
Future requests go to same instance

âš ï¸ Why Sticky Sessions Are Not Ideal
In modern systems:
We store sessions in:
Redis
Database
JWT (stateless auth)
So sticky sessions are often avoided.
Best practice: Make backend stateless

4ï¸âƒ£ Health Checks
ðŸ‘‰ What are Health Checks?
Load balancer periodically checks if a server is healthy.
Example:
GET /health
If response = 200 â†’ Healthy
If response fails â†’ Marked unhealthy

ðŸ”„ What Happens If Instance Fails?
Load balancer stops sending traffic
Traffic goes to other healthy instances
When instance recovers â†’ Added back
ðŸŽ¯ Why Important?
Without health checks:
Traffic could go to crashed servers
Users see errors

# Scaling
ðŸ“ˆ Scaling in Cloud Systems

Scaling means increasing or decreasing your systemâ€™s capacity based on traffic.

There are two types:

1ï¸âƒ£ Vertical Scaling (Scale Up)
Increase CPU, RAM of the same server
Example: t3.medium â†’ t3.large
âœ… Pros
Simple
No architecture change
âŒ Cons
Has limits
Downtime during resize
Single point of failure

2ï¸âƒ£ Horizontal Scaling (Scale Out)
Add more servers
Use Load Balancer to distribute traffic
Example:
1 server â†’ 5 servers during peak traffic
âœ… Pros
High availability
Fault tolerant
Practically unlimited scaling
âŒ Cons
Architecture complexity
Requires stateless design

# ðŸš€ Auto Scaling Groups (ASG)
ðŸ“Œ What is an Auto Scaling Group?
In AWS, Amazon EC2 Auto Scaling automatically:
Launches new EC2 instances
Terminates extra instances
Maintains desired instance count
It works together with:
Elastic Load Balancing
Amazon CloudWatch

You define:
Min instances: 2
Desired: 3
Max: 10
CloudWatch monitors:
CPU usage
Memory
Custom metrics
If CPU > 70%:
ASG launches new EC2
If CPU < 20%:
ASG removes extra EC2

ðŸŽ¯ Scaling Policies
1ï¸âƒ£ Target Tracking
Maintain CPU at 50%
2ï¸âƒ£ Step Scaling
If CPU > 70% â†’ add 2 instances
If CPU > 85% â†’ add 4 instances
3ï¸âƒ£ Scheduled Scaling
Every day 9AM â†’ scale to 6 instances

ðŸ§  Stateless Services
ðŸ“Œ What is Stateless?
A service is stateless when:
Each request is independent
Server does NOT store session data in memory
Example:
Login â†’ JWT token returned
Next request â†’ token validated
No session stored in server
âŒ Stateful Example
User logs in
Session stored in server memory
If request goes to another server â†’ session lost

âœ… Why Stateless Is Important?
Because in horizontal scaling:
Request 1 â†’ Server A
Request 2 â†’ Server C
Request 3 â†’ Server B
If state is stored locally â†’ chaos ðŸ˜…
So modern systems:
Use JWT
Use Redis
Use DB for sessions

# Horizontal Scaling Challenges
Scaling sounds easy but comes with problems.
1ï¸âƒ£ Session Management
Problem:
Multiple servers
Session in memory
Solution:
Redis
JWT
Sticky sessions (temporary fix)
2ï¸âƒ£ Database Bottleneck
Even if you scale 10 servers:
Single DB may crash
Solutions:
Read replicas
Sharding
Caching layer (Redis)
3ï¸âƒ£ Distributed Caching
If cache is local:
Cache inconsistency
Solution:
Central cache (Redis / Memcached)
4ï¸âƒ£ Data Consistency
Multiple servers writing to DB:
Race conditions
Dirty writes
Need:
Transactions
Proper locking
Idempotent APIs
5ï¸âƒ£ Deployment Complexity
Rolling deployments across 10 servers:
Need health checks
Need zero downtime
Use load balancer + ASG
6ï¸âƒ£ Cold Start Time
New instance:
Needs to boot
Install dependencies
Connect to DB
Mitigation:
Keep buffer capacity
Use warm pools

# Logd
ðŸ“Š Monitoring (Crisp Version)
Monitoring = Observing your systemâ€™s health, performance, and failures in real time.
Goal:
Detect issues early
Debug faster
Auto-scale smartly
Alert before users complain
â˜ï¸ CloudWatch
Amazon CloudWatch is AWSâ€™s monitoring service.
It collects:
Metrics
Logs
Events
Alarms
It integrates with:
EC2
Lambda
Load Balancers
RDS
Auto Scaling
ðŸ“ˆ Metrics
Metrics = Numbers over time
Examples:
CPU Utilization
Memory usage
Request count
Error rate (5xx)
Latency
Visualized as:
Graphs
Dashboards
Used for:
Scaling decisions
Performance tracking
ðŸ‘‰ Example:
If CPU > 70% â†’ scale out
ðŸ“œ Logs
Logs = Detailed event records
Examples:
API request logs
Error stack traces
Login attempts
DB query errors
Stored in:
CloudWatch Logs
Used for:
Debugging production issues
Root cause analysis
ðŸ‘‰ Metrics tell something is wrong
ðŸ‘‰ Logs tell what exactly went wrong
ðŸš¨ Alerts (Alarms)
Alerts are triggered when a condition is met.
Example:
CPU > 80% for 5 minutes
5xx errors > 50
Lambda errors > threshold
CloudWatch Alarm can:
Send SNS email
Trigger Auto Scaling
Trigger Lambda
Send Slack notification
ðŸ§  Simple Relationship
Application
   â†“
Logs â†’ Debugging
Metrics â†’ Performance tracking
   â†“
CloudWatch
   â†“
Alarms
   â†“
Notification / Auto Scaling
ðŸŽ¯ Interview Summary
Monitoring = Observe system health
CloudWatch = AWS monitoring tool
Metrics = Numeric performance data
Logs = Detailed event records
Alerts = Notifications when threshold crossed